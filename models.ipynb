{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eNr6gs_mDbBw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "current_date = datetime.now()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QdfQSr5wDixu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "IMPORT DATASET\n",
        "'''\n",
        "path='/content/drive/MyDrive/dash_competition'\n",
        "Train_df = pd.read_csv(path+'/fraudTest.csv')\n",
        "Test_df = pd.read_csv(path+'/fraudTrain.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d3yoqoU9DrpF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "COPY OF THE DATASET\n",
        "'''\n",
        "rawTrain_df = Train_df.copy()\n",
        "rawTest_df = Test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f9qbYVafD2KB"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "DATASET CLEANER\n",
        "'''\n",
        "\n",
        "def df_cleaner(df : pd.DataFrame,name:str):\n",
        "       if not isinstance(df, pd.DataFrame):\n",
        "              raise ValueError('Error: File must be pandas DataFrames.') # Returns error if dataset is not pandas\n",
        "       try:\n",
        "              df['dob'] = pd.to_datetime(df['dob'])\n",
        "              df['age_in_days'] = (current_date - df['dob']).dt.days\n",
        "              df['age'] = df['age_in_days'] / 365\n",
        "              df['age'] = df['age'].apply(math.floor)\n",
        "              df['age'] = df['age'].astype(int) #age of person\n",
        "\n",
        "              df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time']) #transform to date\n",
        "              df['hour'] = df['trans_date_trans_time'].dt.hour #gets hour\n",
        "\n",
        "\n",
        "              df.drop(columns=['Unnamed: 0', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'zip',\n",
        "                     'lat', 'long', 'job','trans_num', 'unix_time', 'merch_lat', 'merch_long','dob',\n",
        "                     'age_in_days','trans_date_trans_time'],inplace=True) # removing not generalized\n",
        "\n",
        "              df.rename(columns={'amt' : 'amount','city_pop':'city_population'}, inplace=True)\n",
        "\n",
        "              df.to_csv(f'{name}.csv')\n",
        "\n",
        "\n",
        "       except (TypeError, ValueError) as err:\n",
        "        # Handle specific error types for better debugging\n",
        "              print(f\"Error cleaning DataFrame: {str(err)}\")  # More descriptive error message\n",
        "\n",
        "       return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NgkQwcVmECdr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "KEEPING CLEANED DATASET\n",
        "'''\n",
        "train_df = df_cleaner(rawTrain_df,'Train_df')\n",
        "test_df = df_cleaner(rawTest_df,'Test_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2o42Mg-JEjr3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "THE PROBLEM OF AN UNBALANCED DATASET.\n",
        "APPLYING ENCODING AND UNDERSAMPLING.\n",
        "ENCODING IS USED TO ADDRESS THE ISSUE OF DUMMY COLUMNS.\n",
        "\n",
        "REGARDING UNDERSAMPLING, I MADE THAT DECISION AFTER DETERMINING THAT\n",
        "OVERSAMPLING WAS NOT A VIABLE OPTION BECAUSE I DID NOT WANT TO INTRODUCE FICTITIOUS DATA.\n",
        "WHEN IT CAME TO BALANCING USING WEIGHTS, THE RESULTS WERE NOT AS EFFECTIVE AS UNDERSAMPLING.\n",
        "\n",
        "IN THIS INSTANCE, THE NUMBER OF TRUE DATA POINTS IN THE FRAUD TABLE WAS SATISFACTORY,\n",
        "SO I OPTED TO MAINTAIN THE SAME QUANTITY FOR FALSE DATA, TAKING RANDOM ROWS.\n",
        "'''\n",
        "\n",
        "df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "df['category'] = df['category'].astype('category')\n",
        "df['gender'] = df['gender'].astype('category')\n",
        "df['state'] = df['state'].astype('category')\n",
        "df['hour'] = df['hour'].astype('category')\n",
        "\n",
        "df['category'] = encoder.fit_transform(df['category'].values.reshape(-1, 1))\n",
        "df['gender'] = encoder.fit_transform(df['gender'].values.reshape(-1, 1))\n",
        "df['state'] = encoder.fit_transform(df['state'].values.reshape(-1, 1))\n",
        "df['hour'] = encoder.fit_transform(df['hour'].values.reshape(-1, 1))\n",
        "\n",
        "df_fraud = df[df['is_fraud'] == 1]\n",
        "df_nofraud1 = df[df['is_fraud'] == 0]\n",
        "\n",
        "# I searched for the quantity of true data points and then randomly selected the same number of rows for the false data.\n",
        "muestra_aleatoria = random.sample(list(range(len(df_nofraud1))), 9651)\n",
        "\n",
        "# select rows of random sample\n",
        "df_nofraud = df_nofraud1.iloc[muestra_aleatoria]\n",
        "\n",
        "df_undersampled = pd.concat([df_fraud, df_nofraud], axis=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7oUcMCdYEljS"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "APPLYING STANDARDSCALER\n",
        "'''\n",
        "\n",
        "X = df_undersampled.drop('is_fraud', axis=1)  # Features\n",
        "y = df_undersampled['is_fraud']  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZfLXFlFFm5d",
        "outputId": "68356c25-003c-4f3d-903e-b24667d7df6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86      1931\n",
            "           1       0.93      0.75      0.83      1930\n",
            "\n",
            "    accuracy                           0.85      3861\n",
            "   macro avg       0.86      0.85      0.85      3861\n",
            "weighted avg       0.86      0.85      0.85      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1820  111]\n",
            " [ 475 1455]] \n",
            "\n",
            " Balanced Accuracy Score: 0.8482258482258482\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Perceptron\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70      1931\n",
            "           1       0.70      0.73      0.71      1930\n",
            "\n",
            "    accuracy                           0.71      3861\n",
            "   macro avg       0.71      0.71      0.71      3861\n",
            "weighted avg       0.71      0.71      0.71      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1317  614]\n",
            " [ 520 1410]] \n",
            "\n",
            " Balanced Accuracy Score: 0.7062937062937062\n",
            "--------------------------------------------------------------------------------------------------\n",
            "SVC(Support Vector Classifier)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89      1931\n",
            "           1       0.92      0.85      0.88      1930\n",
            "\n",
            "    accuracy                           0.89      3861\n",
            "   macro avg       0.89      0.89      0.89      3861\n",
            "weighted avg       0.89      0.89      0.89      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1780  151]\n",
            " [ 292 1638]] \n",
            "\n",
            " Balanced Accuracy Score: 0.8852628852628852\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Ada Boost Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      1931\n",
            "           1       0.94      0.94      0.94      1930\n",
            "\n",
            "    accuracy                           0.94      3861\n",
            "   macro avg       0.94      0.94      0.94      3861\n",
            "weighted avg       0.94      0.94      0.94      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1814  117]\n",
            " [ 115 1815]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9399119399119399\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Gradient Boosting Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      1931\n",
            "           1       0.97      0.96      0.97      1930\n",
            "\n",
            "    accuracy                           0.97      3861\n",
            "   macro avg       0.97      0.97      0.97      3861\n",
            "weighted avg       0.97      0.97      0.97      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1867   64]\n",
            " [  68 1862]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9658119658119658\n",
            "--------------------------------------------------------------------------------------------------\n",
            "XGB Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      1931\n",
            "           1       0.97      0.98      0.98      1930\n",
            "\n",
            "    accuracy                           0.98      3861\n",
            "   macro avg       0.98      0.98      0.98      3861\n",
            "weighted avg       0.98      0.98      0.98      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1881   50]\n",
            " [  32 1898]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9787619787619788\n",
            "--------------------------------------------------------------------------------------------------\n",
            "XGBRF Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96      1931\n",
            "           1       0.96      0.95      0.96      1930\n",
            "\n",
            "    accuracy                           0.96      3861\n",
            "   macro avg       0.96      0.96      0.96      3861\n",
            "weighted avg       0.96      0.96      0.96      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1853   78]\n",
            " [  88 1842]] \n",
            "\n",
            " Balanced Accuracy Score: 0.957005957005957\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1931\n",
            "           1       0.98      0.98      0.98      1930\n",
            "\n",
            "    accuracy                           0.98      3861\n",
            "   macro avg       0.98      0.98      0.98      3861\n",
            "weighted avg       0.98      0.98      0.98      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1883   48]\n",
            " [  43 1887]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9764309764309764\n",
            "--------------------------------------------------------------------------------------------------\n",
            "K Neighbors Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91      1931\n",
            "           1       0.92      0.91      0.91      1930\n",
            "\n",
            "    accuracy                           0.91      3861\n",
            "   macro avg       0.91      0.91      0.91      3861\n",
            "weighted avg       0.91      0.91      0.91      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1773  158]\n",
            " [ 179 1751]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9127169127169127\n",
            "--------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Testing many models\n",
        "\n",
        "clfs = [LogisticRegression(),\n",
        "            Perceptron(),\n",
        "            SVC(),\n",
        "            AdaBoostClassifier(),\n",
        "            GradientBoostingClassifier(),\n",
        "            XGBClassifier(),\n",
        "            XGBRFClassifier(),\n",
        "            RandomForestClassifier(),\n",
        "            KNeighborsClassifier()\n",
        "            ]\n",
        "names = ['Logistic Regression',\n",
        "             'Perceptron',\n",
        "             'SVC(Support Vector Classifier)',\n",
        "             'Ada Boost Classifier',\n",
        "             'Gradient Boosting Classifier',\n",
        "             'XGB Classifier',\n",
        "             'XGBRF Classifier',\n",
        "             'Random Forest Classifier',\n",
        "             'K Neighbors Classifier'\n",
        "             ]\n",
        "\n",
        "ranking_dic={}\n",
        "modelos_dic={}\n",
        "\n",
        "\n",
        "for clf,name in zip(clfs,names):\n",
        "\n",
        "    print(name)\n",
        "\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    clas_report = classification_report(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    ranking_dic[f'{name}'] = accuracy\n",
        "\n",
        "    modelos_dic[f'{name}'] = {'conf_matrix' : conf_matrix}\n",
        "    modelos_dic[f'{name}'].update({'accuracy' : accuracy})\n",
        "\n",
        "\n",
        "    print(f'{clas_report}\\n\\n Confusion Matrix \\n {conf_matrix} \\n\\n Balanced Accuracy Score: {accuracy}')\n",
        "    print(f'--------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T-hKXQVwbexk"
      },
      "outputs": [],
      "source": [
        "ranking_dic = sorted(ranking_dic.items(), key=lambda x: x[1], reverse=True) # making the ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bduWYZfHcA8J",
        "outputId": "3f9d6d12-e325-4768-8558-8ae4fdb8a77d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('XGB Classifier', 0.9787619787619788),\n",
              " ('Random Forest Classifier', 0.9764309764309764),\n",
              " ('Gradient Boosting Classifier', 0.9658119658119658),\n",
              " ('XGBRF Classifier', 0.957005957005957),\n",
              " ('Ada Boost Classifier', 0.9399119399119399),\n",
              " ('K Neighbors Classifier', 0.9127169127169127),\n",
              " ('SVC(Support Vector Classifier)', 0.8852628852628852),\n",
              " ('Logistic Regression', 0.8482258482258482),\n",
              " ('Perceptron', 0.7062937062937062)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranking_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWpgf-fRcA-6",
        "outputId": "67e33a05-b4a1-432b-f0c4-60bd4e92d7a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression :\n",
            "\n",
            "Precisión test fold 1: 0.863414491003907\n",
            "Precisión test fold 2: 0.8516839378238342\n",
            "Precisión test fold 3: 0.858160621761658\n",
            "Precisión test fold 4: 0.8474740932642487\n",
            "Precisión test fold 5: 0.846502590673575\n",
            "Avg. accuracy = 85.34\n",
            "\n",
            "Perceptron :\n",
            "\n",
            "Precisión test fold 1: 0.6237426010698056\n",
            "Precisión test fold 2: 0.7490284974093264\n",
            "Precisión test fold 3: 0.7363989637305699\n",
            "Precisión test fold 4: 0.7697538860103628\n",
            "Precisión test fold 5: 0.6881476683937824\n",
            "Avg. accuracy = 71.34\n",
            "\n",
            "SVC(Support Vector Classifier) :\n",
            "\n",
            "Precisión test fold 1: 0.8922076479366836\n",
            "Precisión test fold 2: 0.8856865284974094\n",
            "Precisión test fold 3: 0.8895725388601037\n",
            "Precisión test fold 4: 0.8792098445595855\n",
            "Precisión test fold 5: 0.873380829015544\n",
            "Avg. accuracy = 88.40\n",
            "\n",
            "Ada Boost Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.9394633365192749\n",
            "Precisión test fold 2: 0.939119170984456\n",
            "Precisión test fold 3: 0.9436528497409327\n",
            "Precisión test fold 4: 0.9387953367875648\n",
            "Precisión test fold 5: 0.9394430051813472\n",
            "Avg. accuracy = 94.01\n",
            "\n",
            "Gradient Boosting Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.9660106142160069\n",
            "Precisión test fold 2: 0.9608160621761658\n",
            "Precisión test fold 3: 0.9621113989637305\n",
            "Precisión test fold 4: 0.9637305699481865\n",
            "Precisión test fold 5: 0.9617875647668395\n",
            "Avg. accuracy = 96.29\n",
            "\n",
            "XGB Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.9753969850931469\n",
            "Precisión test fold 2: 0.979598445595855\n",
            "Precisión test fold 3: 0.9766839378238342\n",
            "Precisión test fold 4: 0.9766839378238342\n",
            "Precisión test fold 5: 0.9792746113989638\n",
            "Avg. accuracy = 97.75\n",
            "\n",
            "XGBRF Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.9572687677113201\n",
            "Precisión test fold 2: 0.9582253886010363\n",
            "Precisión test fold 3: 0.9569300518134715\n",
            "Precisión test fold 4: 0.957577720207254\n",
            "Precisión test fold 5: 0.9546632124352332\n",
            "Avg. accuracy = 95.69\n",
            "\n",
            "Random Forest Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.973131822526284\n",
            "Precisión test fold 2: 0.9760362694300518\n",
            "Precisión test fold 3: 0.9757124352331606\n",
            "Precisión test fold 4: 0.9692357512953368\n",
            "Precisión test fold 5: 0.9718264248704663\n",
            "Avg. accuracy = 97.32\n",
            "\n",
            "K Neighbors Classifier :\n",
            "\n",
            "Precisión test fold 1: 0.9025554605362442\n",
            "Precisión test fold 2: 0.8983160621761658\n",
            "Precisión test fold 3: 0.903821243523316\n",
            "Precisión test fold 4: 0.8928108808290156\n",
            "Precisión test fold 5: 0.903497409326425\n",
            "Avg. accuracy = 90.02\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "HERE IM TESTING CROSS VALIDATION, JUST TO HAVE MORE ROBUST RESULTS\n",
        "'''\n",
        "# Define the number of folds for cross-validation\n",
        "\n",
        "FOLDS = 5\n",
        "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=10)\n",
        "\n",
        "x_train2 = np.array(X_train_scaled)  # Using data of escaled trainings\n",
        "y_train2 = np.array(y_train)\n",
        "\n",
        "defec_accu = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "ranking_dic_avg={}\n",
        "\n",
        "# Iterate over each classifier and perform cross-validation\n",
        "for clfi, name in zip(clfs, names):\n",
        "\n",
        "    print(f'{name} :\\n')\n",
        "    avg_accuracy = 0\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(x_train2, y_train2)):\n",
        "\n",
        "        xi, yi = x_train2[train_idx], y_train2[train_idx]\n",
        "        x_valid, y_valid = x_train2[val_idx], y_train2[val_idx]\n",
        "        clfi.fit(xi, yi)\n",
        "        test_predictions = clfi.predict(x_valid)\n",
        "\n",
        "        balanced_acc = balanced_accuracy_score(y_valid, test_predictions)  # Calculating balanced accuracy\n",
        "        avg_accuracy += balanced_acc\n",
        "        print(f\"Precisión test fold {fold + 1}: {balanced_acc}\")\n",
        "\n",
        "    avg_accuracy /= FOLDS\n",
        "    ranking_dic_avg[f'{name}'] = avg_accuracy\n",
        "\n",
        "    defec_accu.append(round(avg_accuracy * 100, 2))\n",
        "    print(f'Avg. accuracy = {avg_accuracy * 100.0 :.2f}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pGm__31TgDq1"
      },
      "outputs": [],
      "source": [
        "ranking_dic_avg = sorted(ranking_dic_avg.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpCGX209gDta",
        "outputId": "c33be510-adce-486d-e411-f72362a7ef30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('XGB Classifier', 0.9787619787619788)    |     ('XGB Classifier', 0.9775275835471268)\n",
            "('Random Forest Classifier', 0.9764309764309764)    |     ('Random Forest Classifier', 0.97318854067106)\n",
            "('Gradient Boosting Classifier', 0.9658119658119658)    |     ('Gradient Boosting Classifier', 0.9628912420141859)\n",
            "('XGBRF Classifier', 0.957005957005957)    |     ('XGBRF Classifier', 0.956933028153663)\n",
            "('Ada Boost Classifier', 0.9399119399119399)    |     ('Ada Boost Classifier', 0.940094739842715)\n",
            "('K Neighbors Classifier', 0.9127169127169127)    |     ('K Neighbors Classifier', 0.9002002112782334)\n",
            "('SVC(Support Vector Classifier)', 0.8852628852628852)    |     ('SVC(Support Vector Classifier)', 0.8840114777738652)\n",
            "('Logistic Regression', 0.8482258482258482)    |     ('Logistic Regression', 0.8534471469054445)\n",
            "('Perceptron', 0.7062937062937062)    |     ('Perceptron', 0.7134143233227694)\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,9):\n",
        "  print(f'{ranking_dic[i]}    |     {ranking_dic_avg[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PfUngWOdgDwY"
      },
      "outputs": [],
      "source": [
        "# Define random search grids for each model\n",
        "xgb_param_grid = {\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [100, 150, 200, 250],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bynode': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'reg_lambda': [0, 1, 5, 10],\n",
        "    'reg_alpha': [0, 1, 5, 10]\n",
        "}\n",
        "\n",
        "gradient_boosting_param_grid = {\n",
        "    'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
        "    'n_estimators': [100, 150, 200, 250],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "\n",
        "random_forest_param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "}\n",
        "\n",
        "# Define classifiers\n",
        "clfs_bests = [\n",
        "    XGBClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "    ]\n",
        "\n",
        "# Define classifier names\n",
        "names_bests = [\n",
        "    'XGB Classifier',\n",
        "    'Random Forest Classifier',\n",
        "    'Gradient Boosting Classifier',\n",
        "             ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxigyJRfIXuO",
        "outputId": "2cdf0b4b-ab1d-46b8-b740-3740a2d420e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGB Classifier :\n",
            "\n",
            "Best hyperparameters for  XGB Classifier:\n",
            "{'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 5, 'n_estimators': 150, 'min_child_weight': 3, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'colsample_bynode': 1.0} \n",
            "\n",
            "Best cross-validation score: 97.48\n",
            "Test set accuracy:  97.38\n",
            "\n",
            "Random Forest Classifier :\n",
            "\n",
            "Best hyperparameters for  Random Forest Classifier:\n",
            "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'bootstrap': False} \n",
            "\n",
            "Best cross-validation score: 97.31\n",
            "Test set accuracy:  97.46\n",
            "\n",
            "Gradient Boosting Classifier :\n",
            "\n",
            "Best hyperparameters for  Gradient Boosting Classifier:\n",
            "{'subsample': 0.9, 'n_estimators': 100, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 7, 'learning_rate': 0.05} \n",
            "\n",
            "Best cross-validation score: 97.45\n",
            "Test set accuracy:  97.33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# List of random search grids for each model\n",
        "grid_params_best_models = [xgb_param_grid,\n",
        "                           random_forest_param_grid,\n",
        "                           gradient_boosting_param_grid\n",
        "                          ]\n",
        "best_params = []\n",
        "\n",
        "# Perform random search with cross-validation for each model\n",
        "for clfi, name, params in zip(clfs_bests, names_bests, grid_params_best_models):\n",
        "    print(f'{name} :\\n')\n",
        "    avg_accuracy = 0\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=clfi, param_distributions=params, n_iter=5, cv=5)\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Print the best hyperparameters and best score for each model\n",
        "    print(f\"Best hyperparameters for  {name}:\")\n",
        "\n",
        "    print(random_search.best_params_,'\\n')\n",
        "    best_params.append(random_search.best_params_)\n",
        "\n",
        "    print(f\"Best cross-validation score: {random_search.best_score_ * 100.0 :.2f}\")\n",
        "\n",
        "    # Obtener el modelo con los mejores hiperparámetros\n",
        "    best_model_classifier = random_search.best_estimator_\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de prueba\n",
        "    accuracy = best_model_classifier.score(X_test_scaled, y_test)\n",
        "    print(f\"Test set accuracy:  {accuracy * 100.0 :.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtYWFMhPSizo",
        "outputId": "d3683bc0-4293-4a12-ecbf-cefe417ae5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGB Classifier BEST\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      1931\n",
            "           1       0.97      0.98      0.97      1930\n",
            "\n",
            "    accuracy                           0.97      3861\n",
            "   macro avg       0.97      0.97      0.97      3861\n",
            "weighted avg       0.97      0.97      0.97      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1875   56]\n",
            " [  44 1886]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9740999740999741\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Random Forest Classifier BEST\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      1931\n",
            "           1       0.97      0.98      0.97      1930\n",
            "\n",
            "    accuracy                           0.97      3861\n",
            "   macro avg       0.97      0.97      0.97      3861\n",
            "weighted avg       0.97      0.97      0.97      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1873   58]\n",
            " [  42 1888]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9740999740999741\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Gradient Boosting Classifier BEST\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      1931\n",
            "           1       0.97      0.98      0.97      1930\n",
            "\n",
            "    accuracy                           0.97      3861\n",
            "   macro avg       0.97      0.97      0.97      3861\n",
            "weighted avg       0.97      0.97      0.97      3861\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            " [[1873   58]\n",
            " [  48 1882]] \n",
            "\n",
            " Balanced Accuracy Score: 0.9725459725459725\n",
            "--------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Define the provided hyperparameters\n",
        "\n",
        "xgb_params = {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha': 5, 'n_estimators': 150, 'min_child_weight': 7, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0}\n",
        "rf_params = {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
        "gb_params = {'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None, 'max_depth': 7, 'learning_rate': 0.05}\n",
        "\n",
        "# Initialize the classifiers with the custom hyperparameters.\n",
        "clfs = [\n",
        "    XGBClassifier(**xgb_params),\n",
        "    RandomForestClassifier(**rf_params),\n",
        "    GradientBoostingClassifier(**gb_params)\n",
        "]\n",
        "names = [\n",
        "    'XGB Classifier BEST',\n",
        "    'Random Forest Classifier BEST',\n",
        "    'Gradient Boosting Classifier BEST',\n",
        "]\n",
        "\n",
        "ranking_dic={}\n",
        "\n",
        "for clf,name in zip(clfs,names):\n",
        "\n",
        "    print(name)\n",
        "\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    clas_report = classification_report(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    ranking_dic[f'{name}'] = accuracy\n",
        "\n",
        "    modelos_dic[f'{name}'] = {'conf_matrix' : conf_matrix}\n",
        "    modelos_dic[f'{name}'].update({'accuracy' : accuracy})\n",
        "\n",
        "\n",
        "    print(f'{clas_report}\\n\\n Confusion Matrix \\n {conf_matrix} \\n\\n Balanced Accuracy Score: {accuracy}')\n",
        "    print(f'--------------------------------------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ODC0O7-V72s",
        "outputId": "83f917d6-078e-43ae-9339-3418a4445d81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Logistic Regression': {'conf_matrix': array([[1820,  111],\n",
              "         [ 475, 1455]]),\n",
              "  'accuracy': 0.8482258482258482},\n",
              " 'Perceptron': {'conf_matrix': array([[1317,  614],\n",
              "         [ 520, 1410]]),\n",
              "  'accuracy': 0.7062937062937062},\n",
              " 'SVC(Support Vector Classifier)': {'conf_matrix': array([[1780,  151],\n",
              "         [ 292, 1638]]),\n",
              "  'accuracy': 0.8852628852628852},\n",
              " 'Ada Boost Classifier': {'conf_matrix': array([[1814,  117],\n",
              "         [ 115, 1815]]),\n",
              "  'accuracy': 0.9399119399119399},\n",
              " 'Gradient Boosting Classifier': {'conf_matrix': array([[1867,   64],\n",
              "         [  68, 1862]]),\n",
              "  'accuracy': 0.9658119658119658},\n",
              " 'XGB Classifier': {'conf_matrix': array([[1881,   50],\n",
              "         [  32, 1898]]),\n",
              "  'accuracy': 0.9787619787619788},\n",
              " 'XGBRF Classifier': {'conf_matrix': array([[1853,   78],\n",
              "         [  88, 1842]]),\n",
              "  'accuracy': 0.957005957005957},\n",
              " 'Random Forest Classifier': {'conf_matrix': array([[1883,   48],\n",
              "         [  43, 1887]]),\n",
              "  'accuracy': 0.9764309764309764},\n",
              " 'K Neighbors Classifier': {'conf_matrix': array([[1773,  158],\n",
              "         [ 179, 1751]]),\n",
              "  'accuracy': 0.9127169127169127},\n",
              " 'XGB Classifier BEST': {'conf_matrix': array([[1875,   56],\n",
              "         [  44, 1886]]),\n",
              "  'accuracy': 0.9740999740999741},\n",
              " 'Random Forest Classifier BEST': {'conf_matrix': array([[1873,   58],\n",
              "         [  42, 1888]]),\n",
              "  'accuracy': 0.9740999740999741},\n",
              " 'Gradient Boosting Classifier BEST': {'conf_matrix': array([[1873,   58],\n",
              "         [  48, 1882]]),\n",
              "  'accuracy': 0.9725459725459725}}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelos_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbC-bmutXnkj",
        "outputId": "81626dfa-b355-4df8-c60b-0ebd745c1e0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8482258482258482"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelos_dic['Logistic Regression']['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "C9poq_k3XtNz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "for classifier in modelos_dic:\n",
        "  modelos_dic[classifier]['conf_matrix'] = modelos_dic[classifier]['conf_matrix'].tolist()\n",
        "\n",
        "# Convert the confusion matrices from numpy arrays to lists\n",
        "with open('modelos_dic.json', 'w') as json_file:\n",
        "  json.dump(modelos_dic, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pGZDVhgaa1iz"
      },
      "outputs": [],
      "source": [
        "# Save the dictionary as JSON\n",
        "\n",
        "with open('modelos_dic.json', 'r') as json_file:\n",
        "    modelos_dic_cargado = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MSdmZGuKl7ek"
      },
      "outputs": [],
      "source": [
        "MODELS_DATA_NAMES = []\n",
        "MODELS_DATA_ACCURACY =[]\n",
        "\n",
        "for key,values in modelos_dic_cargado.items():\n",
        "  MODELS_DATA_NAMES.append(key)\n",
        "  MODELS_DATA_ACCURACY.append(values['accuracy'])\n",
        "\n",
        "modelo_precisión = list(zip(MODELS_DATA_NAMES, MODELS_DATA_ACCURACY))\n",
        "modelo_precisión_ordenado = sorted(modelo_precisión, key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUu6eMn3l8nH",
        "outputId": "0f6211d3-8f3d-49ee-c6d7-35a1c52f0231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression 0.8482258482258482\n",
            "Perceptron 0.7062937062937062\n",
            "SVC(Support Vector Classifier) 0.8852628852628852\n",
            "Ada Boost Classifier 0.9399119399119399\n",
            "Gradient Boosting Classifier 0.9658119658119658\n",
            "XGB Classifier 0.9787619787619788\n",
            "XGBRF Classifier 0.957005957005957\n",
            "Random Forest Classifier 0.9764309764309764\n",
            "K Neighbors Classifier 0.9127169127169127\n",
            "XGB Classifier BEST 0.9740999740999741\n",
            "Random Forest Classifier BEST 0.9740999740999741\n",
            "Gradient Boosting Classifier BEST 0.9725459725459725\n"
          ]
        }
      ],
      "source": [
        "for i in range (0,12):\n",
        "  print(MODELS_DATA_NAMES[i],MODELS_DATA_ACCURACY[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ck5XcNo731z",
        "outputId": "cced8259-ff58-442a-ca2b-875edd804288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelos ordenados por precisión:\n",
            "[('XGB Classifier', 0.9787619787619788), ('Random Forest Classifier', 0.9764309764309764), ('XGB Classifier BEST', 0.9740999740999741), ('Random Forest Classifier BEST', 0.9740999740999741), ('Gradient Boosting Classifier BEST', 0.9725459725459725), ('Gradient Boosting Classifier', 0.9658119658119658), ('XGBRF Classifier', 0.957005957005957), ('Ada Boost Classifier', 0.9399119399119399), ('K Neighbors Classifier', 0.9127169127169127), ('SVC(Support Vector Classifier)', 0.8852628852628852), ('Logistic Regression', 0.8482258482258482), ('Perceptron', 0.7062937062937062)]\n"
          ]
        }
      ],
      "source": [
        "# Sort the models by accuracy (from highest to lowest)\n",
        "modelos_ordenados = sorted(modelos_dic_cargado.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
        "\n",
        "# List of models sorted by accuracy\n",
        "modelo_precision_ordenado2 = [(nombre, datos['accuracy']) for nombre, datos in modelos_ordenados]\n",
        "\n",
        "print(\"Modelos ordenados por precisión:\")\n",
        "print(modelo_precision_ordenado2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
